# -*- mode: Org; eval: (auto-fill-mode); eval: (flyspell-mode) -*-
#+TITLE: EECS 435 Notes
#+AUTHOR: Stephen Brennan
#+SETUPFILE: config.setup

* 2016-01-14 Thursday

  *Illustration of Closed Patterns, Max-Patterns*

  - If your DB is {<a_1, ..., a_100>, <a_1, ..., a_50>}, and your minimum (absolute)
    support is 1:
  - Closed itemsets:
    - <a_1, ..., a_100>
    - <a_1, ..., a_50>
  - Max itemsets:
    - <a_1, ..., a_100>

  *Algorithm*
  - Subsets of frequent itemsets are frequent as well.
  - So itemsets which are infrequent should not have their supersets generated
    or tested.
  - Method (Apriori Algorithm):
    - Initially, scan DB once to get frequent 1-itemsets
    - Generate length (k+1) candidate itemsets from length k frequent itemsets
    - Test the candidates against DB
    - Terminate when no frequent or candidate set can be generated
  - Seems simple, but there are lost of detail on the algorithm.
  - How to generate candidates?  Two steps:
    - Step 1: self-joining
    - Step 2: pruning
  - Example of candidate generation:
    - l_3 = {abc, abd, acd, ace, bcd}
    - First, compute L_3 * L_3 (cartesian product, sort of)
    - abcd from abc and abd
    - acde from acd and ace
    - However, groups like acde are removed because their superset (ade) are not
      in the previous frequent itemset.
  - There was some Candidate Generation pseudo-code written in a SQL-like syntax
    that was rather confusing.
  - The pruning is pretty simple because you just need to check the k subsets of
    size k-1 to make sure they are all frequent.
  - Counting support of candidates:
    - Candidates are stored in a hash-tree
    - A leaf node contains a list of itemsets and counts.
    - Interior node contains a hash table of something (I hope the slides go up
      soon)
  - The issues for frequent pattern mining are:
    - Multiple scans of transaction database
    - Huge number of candidates
    - Tedious workload of support counting for candidates.
  - The improvements to the algorithm aim to address these concerns.
  - Partitioning:
    - Itemsets that are potentially frequent must be frequent in at least one of
      the partitions.
  - DHP: Reduce the number of candidates
    - A k-itemset whose corresponding hashing bucket count is below the
      threshold cannot be frequent.

  Multiple-Level Association Rules
  - Items frequently form hierarchies, eg milk can be whole, skim, 2%, etc.
  - May want to have different support thresholds for lower levels of the
    hierarchy.
  - Need to filter "redundant" association rules where child items are involved
    but they add no more information to the parent rule.

  Constraint based mining
  - Anti-monotone constraint: when an itemset S violates a constraint, so do all
    supersets of S.
  - Monotone constraint: when an itemset S satisfies a constraint, so do all
    supersets of S.

* 2016-01-12 Tuesday

** Introductory Material

  I was late (and probably will be late frequently due to another class).
  Hopefully I didn't miss too much.

  Grading:
  - 30% paper presentation
  - 10% attendance, participation
  - 60% project

  Paper presentation:
  - Group of two
  - Present one or two papers.
  - Lead discussion.
  - May be helpful to read a few references.

  Project:
  - Best to come up with your own ideas, but he does have some ideas on his
    slides.
  - Project proposal (3-5 pages, due Feb 16) should include:
    - Title, idea, survey of related work, data source, key
      algorithms/technology, and what you expect to submit at the end of the
      semester.
  - Final report (1-20 pages, due April 21) must include:
    - Comprehensive description of your project
    - Project idea, extended survey of related work, result, etc.
    - What worked, what didn't work, what surprised you, etc.

  Data mining conferences:
  - ACM-SIGKDD
  - IEEE-ICDM
  - SIAM-DM
  - PKDD
  - PAKDD

  Journal:
  - Data Mining and Knowledge Discovery
  - KDD Explorations

  Other references can be found in the conferences and journals for the fields:
  - Database systems
  - Artificial Intelligence
  - Statistics
  - Bioinformatics

** Chapter 5
   *Mining Frequent Patterns, Association, and Correlations*

   - Original slides at: http://www.cs.uiuc.edu/homes/hanj/bk2/slidesindex.htm
     (broken link).
   - Frequent pattern analysis - finding items, subsequences, substructures,
     etc, that occur frequently in a data set.
     - Related - frequent itemsets, association rule mining
     - Agrawal, Imielinski, and Swami '93 introduced these ideas
   - Motivation is to find regularities, rules, etc that give you insight into
     data.  For instance:
     - Beer and diapers are frequently purchased together.
     - What are subsequent purchases after a PC?
   - Itemset: a set of items
   - k-itemset: an itemset containing k items
   - Call the set of all items \(I = \{I_1, \dots, I_m\}\)
   - \(T \subseteq I\) is a transaction, and has a transaction id.
   - An association rule is of the form \(A \to B\), with minimum support and
     confidence, where \(A \subset I\), \(B \subset I\), \(A \cap B =
     \emptyset\).
   - Support (for \(A \to B\)) is \(Pr[A \cup B \subseteq T]\).
     - That is, the probability that a transaction contains all of A and B.
     - As a percentage, also referred to as relative support.
     - As a number, referred to as the absolute support
   - Confidence (for \(A \to B\)) is \(Pr[B \subset T | A \subset T]\)
     - That is, the conditional probability that a transaction contains B, given
       it contains A.
     - \(Pr[B \subset T | A \subset T] = \frac{Pr[B \cup A \subseteq T]}{Pr[A
       \subset T]} = \frac{support(A \cup B)}{support(A)}\)
   - Confidence can be easily derived from the support of \(A\) and \(A \cup
     B\).  Which means you can "reduce" this problem to finding itemsets with
     high confidence, and then looking for disjoint pairs with high confidence.
   - Big patterns have lots of subsets, and therefore lots of other frequent
     patterns.  So, you want to find closed patterns and max-patterns.
   - Closed pattern: X is closed if X is frequent and there is no super-pattern
     \(Y \supset X\) with the same support as X.
   - An itemset X is a max-pattern if X is frequent and there is no frequent
     super-pattern \(Y \supset X\).
     - A "maximal" frequent super-pattern.
     - All max-patterns are closed.
